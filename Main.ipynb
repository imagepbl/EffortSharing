{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preambule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import savgol_filter\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data reader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ==================================== #\n",
      "# DATAREADING class                    #\n",
      "# startyear:  2021\n",
      "# ==================================== #\n",
      "- Reading general data\n",
      "- Reading GDP and population data from SSPs\n",
      "- Reading UN population data and gapminder, processed by OWID (for past population)\n",
      "- Read Human Development Index data\n",
      "- Reading historical emissions (jones)\n",
      "- Read AR6 data\n",
      "- Get relationship between CO2 budgets and non-co2 reduction in 2050\n",
      "- Computing global nonco2 trajectories\n",
      "- Get global CO2 budgets\n",
      "- Computing global co2 trajectories\n",
      "- Reading baseline emissions\n",
      "- Reading NDC data\n",
      "- Reading NDC data from Climate resource\n",
      "- Merging xrarray object\n",
      "- Add country groups\n",
      "- Save important files\n"
     ]
    }
   ],
   "source": [
    "import class_datareading\n",
    "reload(class_datareading)\n",
    "from class_datareading import datareading\n",
    "\n",
    "datareader = datareading()\n",
    "datareader.read_general()\n",
    "datareader.read_ssps()\n",
    "datareader.read_undata()\n",
    "datareader.read_hdi()\n",
    "datareader.read_historicalemis_jones()\n",
    "datareader.read_ar6()\n",
    "datareader.relation_budget_nonco2()\n",
    "datareader.determine_global_nonco2_trajectories()\n",
    "datareader.determine_global_budgets()\n",
    "datareader.determine_global_co2_trajectories()\n",
    "datareader.read_baseline()\n",
    "datareader.read_ndc()\n",
    "datareader.read_ndc_climateresource()\n",
    "datareader.merge_xr()\n",
    "datareader.add_country_groups()\n",
    "datareader.save()\n",
    "datareader.country_specific_datareaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import class_allocation\n",
    "reload(class_allocation)\n",
    "from class_allocation import allocation\n",
    "\n",
    "allocator = allocation(\"USA\", lulucf='incl', gas='GHG')\n",
    "allocator.gf()\n",
    "allocator.pc()\n",
    "allocator.pcc()\n",
    "allocator.pcb()\n",
    "allocator.ecpc()\n",
    "allocator.ap()\n",
    "allocator.gdr()\n",
    "allocator.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocations specifically for Norway and Netherlands if you want to harmonize to national data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOR incl GHG xr_dataread.nc done\n",
      "NOR incl GHG xr_dataread_nor.nc done\n",
      "NOR incl CO2 xr_dataread.nc done\n",
      "NOR incl CO2 xr_dataread_nor.nc done\n",
      "NOR excl GHG xr_dataread.nc done\n",
      "NOR excl GHG xr_dataread_nor.nc done\n",
      "NOR excl CO2 xr_dataread.nc done\n",
      "NOR excl CO2 xr_dataread_nor.nc done\n"
     ]
    }
   ],
   "source": [
    "import class_allocation\n",
    "reload(class_allocation)\n",
    "from class_allocation import allocation\n",
    "\n",
    "for lulucf in ['incl', 'excl']:\n",
    "    for gas in ['GHG', 'CO2']:\n",
    "        for dataread_file in ['xr_dataread.nc', 'xr_dataread_nor.nc']: # This is only necessary if for a country a specific historical emissions profile is required beyond what is in Jones (e.g. Norway was requested)\n",
    "            allocator = allocation('NOR', lulucf=lulucf, gas=gas, dataread_file=dataread_file)\n",
    "            allocator.gf()\n",
    "            allocator.pc()\n",
    "            allocator.pcc()\n",
    "            allocator.pcb()\n",
    "            allocator.ecpc()\n",
    "            allocator.ap()\n",
    "            allocator.gdr()\n",
    "            allocator.save()\n",
    "            print('NOR', lulucf, gas, dataread_file, 'done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import class_allocation\n",
    "reload(class_allocation)\n",
    "from class_allocation import allocation\n",
    "\n",
    "regions_iso = np.load(\"K:/Data/Data_effortsharing/DataUpdate_ongoing/all_regions.npy\", allow_pickle=True)\n",
    "for cty in tqdm(regions_iso[180:]):\n",
    "    allocator = allocation(cty, lulucf='incl', gas='GHG')\n",
    "    allocator.gf()\n",
    "    allocator.pc()\n",
    "    allocator.pcc()\n",
    "    allocator.pcb()\n",
    "    allocator.ecpc()\n",
    "    allocator.ap()\n",
    "    allocator.gdr()\n",
    "    allocator.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocation rules combining approaches (Robiou paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import class_allocation_combinedapproaches\n",
    "reload(class_allocation_combinedapproaches)\n",
    "from class_allocation_combinedapproaches import allocation_comb\n",
    "\n",
    "allocator = allocation_comb(lulucf='excl', gas='GHG')\n",
    "allocator.ecpc()\n",
    "allocator.discounting_historical_emissions()\n",
    "allocator.approach1gdp()\n",
    "allocator.approach1hdi()\n",
    "allocator.approach2()\n",
    "allocator.approach2_transition()\n",
    "allocator.combine()\n",
    "allocator.get_relation_2030emis_temp()\n",
    "allocator.determine_tempoutcomes()\n",
    "allocator.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature NDC-alignment metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ==================================== #\n",
      "# Initializing tempaligning class        #\n",
      "# ==================================== #\n",
      "- Determine relation between 2030-emissions and temperature outcome\n",
      "- Determine temperature metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:11<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Save\n"
     ]
    }
   ],
   "source": [
    "import class_tempalign\n",
    "reload(class_tempalign)\n",
    "from class_tempalign import tempaligning\n",
    "\n",
    "tempaligner = tempaligning() # FIRST RUN AGGREGATOR FOR THIS!! (2030 alloc)\n",
    "tempaligner.get_relation_2030emis_temp()\n",
    "tempaligner.determine_tempoutcomes()\n",
    "tempaligner.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading policy scenarios from ENGAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ==================================== #\n",
      "# Initializing policyscenadding class  #\n",
      "# ==================================== #\n",
      "- Read ENGAGE scenarios and change region namings\n",
      "- Filter correct scenarios and convert to xarray object\n",
      "- Add to overall xrobject\n"
     ]
    }
   ],
   "source": [
    "import class_policyscens\n",
    "reload(class_policyscens)\n",
    "from class_policyscens import policyscenadding\n",
    "\n",
    "policyscenner = policyscenadding()\n",
    "policyscenner.read_engage_data()\n",
    "policyscenner.filter_and_convert()\n",
    "policyscenner.add_to_xr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ==================================== #\n",
      "# Initializing vardecomposing class    #\n",
      "# ==================================== #\n",
      "- Starting sobols for fixed years, over many countries\n",
      "  Starting with 2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:30,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting with 2035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:19,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting with 2040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:16,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting with 2045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:12,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting with 2050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:12,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting with 2055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:14,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting with 2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:12,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting with 2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:10,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting with 2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:10,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting with 2075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:09,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting with 2080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:10,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting with 2085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:14,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting with 2090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:09,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting with 2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:09,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting with 2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [02:12,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Save global results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import class_variancedecomp\n",
    "reload(class_variancedecomp)\n",
    "from class_variancedecomp import vardecomposing\n",
    "\n",
    "vardecomposer = vardecomposing(startyear=2021, gas='GHG', lulucf='incl')\n",
    "vardecomposer.sobolindices = {}\n",
    "print('- Starting sobols for fixed years, over many countries')\n",
    "timeseries = np.arange(2030, 2101, 5)\n",
    "for year in timeseries:\n",
    "    print('  Starting with', year)\n",
    "    xr_cty, ar_time, array_dims, array_inputs, problem, samples = vardecomposer.prepare_global_sobol(year)\n",
    "    vardecomposer.sobolindices[year] = vardecomposer.apply_decomposition(xr_cty, ar_time, array_dims, array_inputs, problem, samples)\n",
    "vardecomposer.save(array_dims, timeseries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
